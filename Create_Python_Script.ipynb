{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Create the Python Script\n",
    "\n",
    "In the cell below, you will need to complete the Python script and run the cell to generate the file using the magic `%%writefile` command. Your main task is to complete the following methods for the `PersonDetect` class:\n",
    "* `load_model`\n",
    "* `predict`\n",
    "* `draw_outputs`\n",
    "* `preprocess_outputs`\n",
    "* `preprocess_inputs`\n",
    "\n",
    "For your reference, here are all the arguments used for the argument parser in the command line:\n",
    "* `--model`:  The file path of the pre-trained IR model, which has been pre-processed using the model optimizer. There is automated support built in this argument to support both FP32 and FP16 models targeting different hardware.\n",
    "* `--device`: The type of hardware you want to load the model on (CPU, GPU, MYRIAD, HETERO:FPGA,CPU)\n",
    "* `--video`: The file path of the input video.\n",
    "* `--output_path`: The location where the output stats and video file with inference needs to be stored (results/[device]).\n",
    "* `--max_people`: The max number of people in queue before directing a person to another queue.\n",
    "* `--threshold`: The probability threshold value for the person detection. Optional arg; default value is 0.60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting person_detect.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile person_detect.py\n",
    "\n",
    "\"\"\"\n",
    "SMART QUEUE SYSTEM USING INTEL DEVCLOUD\n",
    "Created on Mon Jun 22 17:11:05 2020\n",
    "\n",
    "@author: Abdul Basit\n",
    "\"\"\"\n",
    "# IMPORTING REQUIRED LIBRARIES FOR THE PROJECT\n",
    "import numpy as np\n",
    "import time\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "import os\n",
    "import cv2 # Importing opencv\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "class Queue:\n",
    "    '''\n",
    "    Class for dealing with queues\n",
    "    Performs operations for queues like adding , getting the queues \n",
    "    and checking the coordinates\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # A list contains the queues data\n",
    "        self.queues=[]\n",
    "\n",
    "    def add_queue(self, points):\n",
    "        # Add points to queues\n",
    "        self.queues.append(points)\n",
    "\n",
    "    def get_queues(self, image):\n",
    "        # Get queue from iamges\n",
    "        # yield frame of image after extracting coordinates\n",
    "        for q in self.queues:\n",
    "            x_min, y_min, x_max, y_max=q\n",
    "            frame=image[y_min:y_max, x_min:x_max]\n",
    "            yield frame\n",
    "    \n",
    "    def check_coords(self, coords, frame):\n",
    "        # Check coordinates for queues\n",
    "        # Return frame\n",
    "        d={k+1:0 for k in range(len(self.queues))}\n",
    "        for coord in coords:\n",
    "            for i, q in enumerate(self.queues):\n",
    "                if coord[0]>q[0] and coord[2]<q[2]:\n",
    "                    d[i+1]+=1\n",
    "                   \n",
    "        return d, frame\n",
    "\n",
    "\n",
    "class PersonDetect:\n",
    "    '''\n",
    "    Class for the Person Detection Model.\n",
    "    Performs prediction, draw outputs, preprocessed inputs and outputs\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model_name, device, threshold=0.60):\n",
    "        # Set threshold to 0.6, it can be changed as per application requirement\n",
    "        ''' Inits PersonDetect class with model_name (weights and structure), device, threshold, initial width and height'''\n",
    "        self.model_weights=model_name+'.bin'\n",
    "        # String contains model weights path i.e. .bin\n",
    "        self.model_structure=model_name+'.xml'\n",
    "        # String contains model structure path i.e. .xml\n",
    "        self.device=device\n",
    "        # String contains device name\n",
    "        self.threshold=threshold\n",
    "        # String contains threshold value as floating point\n",
    "        self.initial_w = ''\n",
    "        # String contains initial width that will be used in draw_output function to extract boundaries\n",
    "        self.initial_h = ''\n",
    "        # String contains initial height that will be used in draw_output function to extract boundaries\n",
    "        \n",
    "        try:\n",
    "            self.model=IENetwork(self.model_structure, self.model_weights)\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Could not Initialise the network. Have you enterred the correct model path?\")\n",
    "        \n",
    "        # A tuple of the input shape : input_shape\n",
    "        # A list of output name : soutput_name\n",
    "        # A tuple of the output shape : output_shape\n",
    "       \n",
    "        \n",
    "        self.input_name=next(iter(self.model.inputs))\n",
    "        # Get the name of the input node\n",
    "        self.input_shape=self.model.inputs[self.input_name].shape\n",
    "        self.output_name=next(iter(self.model.outputs))\n",
    "        # Get the name of the output node\n",
    "        self.output_shape=self.model.outputs[self.output_name].shape\n",
    "\n",
    "    def load_model(self):\n",
    "        ''' Load the model\n",
    "        '''\n",
    "        self.core = IECore()\n",
    "        self.net = self.core.load_network(network=self.model, device_name=self.device, num_requests=1)\n",
    "        # IECore object : core\n",
    "        # Loaded net object:  net\n",
    "        # raise NotImplementedError\n",
    "        \n",
    "        \n",
    "    def predict(self, image):\n",
    "        ''' Make asynchronous predictions from images\n",
    "        List of image data: image\n",
    "        '''\n",
    "        input_img = self.preprocess_input(image)\n",
    "        # Running Inference in a loop on the same image\n",
    "        input_dict = {self.input_name:input_img}\n",
    "        \n",
    "        # Start asynchronous inference for specified request.\n",
    "        self.net.start_async(request_id=0,inputs=input_dict)\n",
    "        infer_status = self.net.requests[0].wait(-1)\n",
    "        if infer_status == 0:\n",
    "            results = self.net.requests[0].outputs[self.output_name]\n",
    "            image,coords = self.draw_outputs(results, image)\n",
    "        return coords,image\n",
    "        # returns coords and image\n",
    "        #raise NotImplementedError\n",
    "    \n",
    "    def draw_outputs(self, results, frame):\n",
    "        initial_point=0 \n",
    "        # Represent top left corner of rectangle\n",
    "        ending_point=0 \n",
    "        # Represent bottom right corner of rectangle\n",
    "        det=[]\n",
    "        # Set initial value i.e. coordinates list, two points/coordinates for rectangle\n",
    "        \n",
    "        \"\"\"\n",
    "        It Draws outputs (predictions) on image.\n",
    "        It takes coords/results : The coordinates of predictions.\n",
    "            and image/ frame: The image on which boxes need to be drawn.\n",
    "        It will return\n",
    "            1) the frame\n",
    "            2) bounding boxes above threshold\n",
    "        \"\"\"\n",
    "        # Rectangle need two coordinates, one is top left corner and second one is bottom right\n",
    "        # Top left corner will be (xmin,ymin)\n",
    "        # Bottom right corner will be (xmax,ymax)\n",
    "        \n",
    "        # Loop through detections and determine what and where the objects are in the image\n",
    "        # For each detection , it has 7 values i.e. [image_id,label,conf,x_min,y_min,x_max,y_max]\n",
    "        # image_id - ID of the image in the batch\n",
    "        # label - predicted class ID\n",
    "        # conf - confidence for the predicted class\n",
    "        # (x_min, y_min) - coordinates of the top left bounding box corner\n",
    "        # (x_max, y_max) - coordinates of the bottom right bounding box corner\n",
    "        for obj in results[0][0]:\n",
    "            # Draw bounding box for object when it's probability is more than the specified threshold\n",
    "            \n",
    "            if obj[2] > self.threshold: # Extract the confidence and compare with threshold value\n",
    "                xmin = int(obj[3] * self.initial_w)\n",
    "                ymin = int(obj[4] * self.initial_h)\n",
    "                xmax = int(obj[5] * self.initial_w)\n",
    "                ymax = int(obj[6] * self.initial_h)\n",
    "                initial_point = (xmin,ymin)\n",
    "                ending_point = (xmax,ymax)\n",
    "                # Use cv2.rectangle() method to draw a rectangle around detection \n",
    "                # Draw a rectangle with colored line (can be changed as per requirement) borders of thickness of 1 px\n",
    "                # cv2. rectangle(img, pt1, pt2, color, thickness)\n",
    "                cv2.rectangle(frame, initial_point, ending_point, (255, 0, 0), 2)\n",
    "                rec_points = [xmin,ymin,xmax,ymax]\n",
    "                # Can also be written as rec_points=[initial_points,ending_points]\n",
    "                det.append(rec_points)\n",
    "               \n",
    "        return frame,det\n",
    "        #raise NotImplementedError\n",
    "\n",
    "    def preprocess_outputs(self, outputs):\n",
    "        \"\"\"\n",
    "        Preprocess the outputs.\n",
    "        It takes the output from predictions i.e outputs\n",
    "        It will return preprocessed dictionary.\n",
    "        \"\"\"\n",
    "        out_dict = {}\n",
    "        for output in outputs:\n",
    "            output_name = self.output_name\n",
    "            output_img = output\n",
    "            out_dict[output_name] = output_img\n",
    "        \n",
    "        return out_dict\n",
    "    \n",
    "        return output\n",
    "        #raise NotImplementedError\n",
    "        \n",
    "    def preprocess_input(self, image):\n",
    "        ''' It preproprocessed input\n",
    "        An input image in the format [BxCxHxW], where:\n",
    "\n",
    "            B - batch size (here we use n)\n",
    "            C - number of channels\n",
    "            H - image height\n",
    "            W - image width\n",
    "        '''\n",
    "        n, c, h, w = self.input_shape\n",
    "        # Extracting n,c,h and w from input image\n",
    "        image = cv2.resize(image, (w, h),interpolation = cv2.INTER_AREA)\n",
    "        # We used INTER_AREA for interpolation as i has resamping using pixel area relation and preferred method for image decimation\n",
    "        \n",
    "        # Change image from HWC to CHW\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = image.reshape((n, c, h, w))\n",
    "        \n",
    "        return image\n",
    "        #raise NotImplementedError\n",
    "        ''' Here we can also use these code instead of above code:\n",
    "            image = cv2.resize(image, (self.input_shape[3], self.input_shape[2]))\n",
    "            image = image.transpose(2, 0, 1)\n",
    "            image = image.reshape(1, *image.shape)\n",
    "            return image\n",
    "        OR\n",
    "            image = cv2.resize(image, (w, h))\n",
    "            pp_image = image.transpose((2, 0, 1))\n",
    "            pp_image = pp_image.reshape(1, *pp_image.shape)\n",
    "            return pp_image\n",
    "        '''\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    model=args.model\n",
    "    device=args.device\n",
    "    video_file=args.video\n",
    "    max_people=args.max_people\n",
    "    threshold=args.threshold\n",
    "    output_path=args.output_path\n",
    "    start_model_load_time=time.time()\n",
    "    pd= PersonDetect(model, device, threshold)\n",
    "    pd.load_model()\n",
    "    total_model_load_time = time.time() - start_model_load_time\n",
    "\n",
    "    queue=Queue()\n",
    "    try:\n",
    "        queue_param=np.load(args.queue_param)\n",
    "        for q in queue_param:\n",
    "            queue.add_queue(q)\n",
    "    except:\n",
    "        print(\"error loading queue param file\")\n",
    "\n",
    "    try:\n",
    "        cap=cv2.VideoCapture(video_file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Cannot locate video file: \"+ video_file)\n",
    "    except Exception as e:\n",
    "        print(\"Something else went wrong with the video file: \", e)\n",
    "    pd.initial_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    pd.initial_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    # In opencv we can replace CAP_PROP_FRAME_WIDTH with (3)\n",
    "    # In the same maner we can replace CAP_PROP_FRAME_HEIGHT with (4)\n",
    "    video_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    out_video = cv2.VideoWriter(os.path.join(output_path, 'output_video.mp4'), cv2.VideoWriter_fourcc(*'avc1'), fps, (pd.initial_w, pd.initial_h), True)\n",
    "    \n",
    "    counter=0\n",
    "    start_inference_time=time.time()\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame=cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            counter+=1\n",
    "            coords, image= pd.predict(frame)\n",
    "            num_people, image= queue.check_coords(coords,image)\n",
    "            print(f\"Total People in frame = {len(coords)}\")\n",
    "            print(f\"Number of people in queue = {num_people}\")\n",
    "            out_text=\"\"\n",
    "            y_pixel=45\n",
    "            \n",
    "            for k, v in num_people.items():\n",
    "                out_text += f\"No. of People in Queue {k} is {v} \"\n",
    "                if v >= int(max_people):\n",
    "                    out_text += f\" Queue full; Please move to next Queue \"\n",
    "                cv2.putText(image, out_text, (15, y_pixel), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "                out_text=\"\"\n",
    "                y_pixel+=40\n",
    "            out_video.write(image)\n",
    "            \n",
    "        total_time=time.time()-start_inference_time\n",
    "        total_inference_time=round(total_time, 1)\n",
    "        fps=counter/total_inference_time\n",
    "\n",
    "        with open(os.path.join(output_path, 'stats.txt'), 'w') as f:\n",
    "            f.write(str(total_inference_time)+'\\n')\n",
    "            f.write(str(fps)+'\\n')\n",
    "            f.write(str(total_model_load_time)+'\\n')\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    except Exception as e:\n",
    "        print(\"Could not run Inference: \", e)\n",
    "\n",
    "\n",
    "#The argparse module makes it easy to write user-friendly command-line interfaces\n",
    "#Add required  groups\n",
    "#Create the arguments\n",
    "if __name__=='__main__':\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument('--model', required=True)\n",
    "    parser.add_argument('--device', default='CPU')\n",
    "    parser.add_argument('--video', default=None)\n",
    "    parser.add_argument('--queue_param', default=None)\n",
    "    parser.add_argument('--output_path', default='/results')\n",
    "    parser.add_argument('--max_people', default=2)\n",
    "    parser.add_argument('--threshold', default=0.60)\n",
    "    \n",
    "    args=parser.parse_args()\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step\n",
    "\n",
    "Now that you've run the above cell and created your Python script, you will create your job submission shell script in the next workspace.\n",
    "\n",
    "**Note**: As a reminder, if you need to make any changes to the Python script, you can come back to this workspace to edit and run the above cell to overwrite the file with your changes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
